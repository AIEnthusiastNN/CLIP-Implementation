#Learning Transferable Visual Models From Natural Language Supervision

Summary of CLIP modelâ€™s approach, from Learning Transferable Visual Models From Natural Language Supervision paper


# CLIP-Implementation
In January of 2021 that OpenAI announced two new models: DALL-E and CLIP, both multi-modality models connecting texts and images in some way. In this repo, we are going to implement CLIP model from scratch in PyTorch. OpenAI has open-source. I simplify it and build CLIP model on Keras and PyTorch

Radford, Alec, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry et al. "Learning transferable visual models from natural language supervision." In International conference on machine learning, pp. 8748-8763. PMLR, 2021.
